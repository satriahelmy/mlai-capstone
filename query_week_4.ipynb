{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "137125cb-1683-48c3-828e-db08331cb7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 24 input vectors and 51 outputs.\n",
      "\n",
      "=== Function 1 (2D) ===\n",
      "  Data size: 13 points, y range: [-0.0036, 64.0000]\n",
      "  Best predicted output: 40.772821\n",
      "  Query to submit: 0.016007-0.605447\n",
      "\n",
      "=== Function 2 (2D) ===\n",
      "  Data size: 13 points, y range: [-0.0656, 3.1124]\n",
      "  Best predicted output: 1.707927\n",
      "  Query to submit: 0.728518-0.696110\n",
      "\n",
      "=== Function 3 (3D) ===\n",
      "  Data size: 18 points, y range: [-0.3989, 71.0000]\n",
      "  Best predicted output: 59.816766\n",
      "  Query to submit: 0.049613-0.978013-0.976174\n",
      "\n",
      "=== Function 4 (4D) ===\n",
      "  Data size: 33 points, y range: [-32.6257, 64.0000]\n",
      "  Best predicted output: 24.649696\n",
      "  Query to submit: 0.248046-0.305402-0.210307-0.342861\n",
      "\n",
      "=== Function 5 (4D) ===\n",
      "  Data size: 23 points, y range: [0.1129, 1787.3908]\n",
      "  Best predicted output: 2166.909172\n",
      "  Query to submit: 0.022283-0.065706-0.891871-0.948172\n",
      "\n",
      "=== Function 6 (5D) ===\n",
      "  Data size: 23 points, y range: [-2.5712, 64.0000]\n",
      "  Best predicted output: 62.366539\n",
      "  Query to submit: 0.019569-0.199363-0.004800-0.829687-0.004011\n",
      "\n",
      "=== Function 7 (6D) ===\n",
      "  Data size: 33 points, y range: [-0.0787, 1.3650]\n",
      "  Best predicted output: 1.662763\n",
      "  Query to submit: 0.066115-0.485528-0.272001-0.020815-0.355857-0.854939\n",
      "\n",
      "=== Function 8 (8D) ===\n",
      "  Data size: 43 points, y range: [5.5922, 64.0000]\n",
      "  Best predicted output: 60.020369\n",
      "  Query to submit: 0.071434-0.882070-0.098568-0.784342-0.713216-0.528971-0.274082-0.860539\n",
      "\n",
      "ðŸ’¾ All week 4 queries saved to week4_queries.txt\n",
      "âœ… DONE â€” Copy each query into the Capstone portal.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "base_path = \"data/\"\n",
    "inputs_txt = \"week3/inputs.txt\"   # file dari email minggu lalu\n",
    "outputs_txt = \"week3/outputs.txt\"\n",
    "n_candidates = 2000\n",
    "\n",
    "# === 1. LOAD INPUTS ===\n",
    "def load_inputs(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        text = f.read().strip()\n",
    "\n",
    "    # Pecah tiap array(...) jadi satu per function\n",
    "    chunks = re.findall(r'array\\((.*?)\\)', text, re.DOTALL)\n",
    "\n",
    "    inputs = []\n",
    "    for ch in chunks:\n",
    "        # Bersihkan karakter aneh dan pecah angka\n",
    "        numbers = [float(x) for x in re.findall(r'[-+]?\\d*\\.\\d+|\\d+', ch)]\n",
    "        inputs.append(np.array(numbers))\n",
    "    return inputs\n",
    "\n",
    "# === 2. LOAD OUTPUTS ===\n",
    "def load_outputs(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        text = f.read().strip()\n",
    "\n",
    "    # Ambil angka dari np.float64(...)\n",
    "    numbers = [float(x) for x in re.findall(r'[-+]?\\d*\\.\\d+|\\d+', text)]\n",
    "    return np.array(numbers)\n",
    "\n",
    "# === LOAD FROM EMAIL ===\n",
    "new_inputs = load_inputs(inputs_txt)\n",
    "new_outputs = load_outputs(outputs_txt)\n",
    "\n",
    "print(f\"âœ… Loaded {len(new_inputs)} input vectors and {len(new_outputs)} outputs.\")\n",
    "\n",
    "# === 3. PROCESS EACH FUNCTION ===\n",
    "queries_out = []\n",
    "\n",
    "for i in range(1, 9):\n",
    "    folder = os.path.join(base_path, f\"function_{i}\")\n",
    "    input_file = os.path.join(folder, \"week3_inputs.npy\")\n",
    "    output_file = os.path.join(folder, \"week3_outputs.npy\")\n",
    "\n",
    "    # Load minggu lalu\n",
    "    X_prev = np.load(input_file)\n",
    "    y_prev = np.load(output_file)\n",
    "\n",
    "    # Gabungkan dengan hasil minggu lalu\n",
    "    X_combined = np.vstack([X_prev, new_inputs[i - 1].reshape(1, -1)])\n",
    "    y_combined = np.append(y_prev, new_outputs[i - 1])\n",
    "\n",
    "    # Simpan versi baru\n",
    "    np.save(os.path.join(folder, \"week4_inputs.npy\"), X_combined)\n",
    "    np.save(os.path.join(folder, \"week4_outputs.npy\"), y_combined)\n",
    "\n",
    "    dim = X_combined.shape[1]\n",
    "    print(f\"\\n=== Function {i} ({dim}D) ===\")\n",
    "    print(f\"  Data size: {len(X_combined)} points, y range: [{y_combined.min():.4f}, {y_combined.max():.4f}]\")\n",
    "\n",
    "    # === TRAIN MLP MODEL ===\n",
    "    model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        MLPRegressor(\n",
    "            hidden_layer_sizes=(64, 32),\n",
    "            activation='relu',\n",
    "            solver='adam',\n",
    "            learning_rate_init=0.01,\n",
    "            max_iter=2000,\n",
    "            random_state=42\n",
    "        )\n",
    "    )\n",
    "    model.fit(X_combined, y_combined)\n",
    "\n",
    "    # === GENERATE NEW QUERY ===\n",
    "    candidates = np.random.uniform(0, 1, (n_candidates, dim))\n",
    "    preds = model.predict(candidates)\n",
    "    best_idx = np.argmax(preds)\n",
    "    best_query = candidates[best_idx]\n",
    "\n",
    "    query_str = \"-\".join([f\"{x:.6f}\" for x in best_query])\n",
    "    print(f\"  Best predicted output: {preds[best_idx]:.6f}\")\n",
    "    print(f\"  Query to submit: {query_str}\")\n",
    "\n",
    "    queries_out.append(f\"Function {i}: {query_str}\")\n",
    "\n",
    "# === 4. SAVE QUERIES ===\n",
    "with open(\"week4_queries.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(queries_out))\n",
    "\n",
    "print(\"\\nðŸ’¾ All week 4 queries saved to week4_queries.txt\")\n",
    "print(\"âœ… DONE â€” Copy each query into the Capstone portal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c9ae9e-e7d0-46d0-b254-4c45883c4102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
