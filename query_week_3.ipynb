{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58df6287-efd6-412f-8041-c496d2d90650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 8 new inputs and 8 outputs (latest batch).\n",
      "\n",
      "=== Function 1 (2D) ===\n",
      "  Data size: (12, 2), Output range: [-0.0036, 0.0000]\n",
      "  Best predicted output: -0.0018\n",
      "  Query to submit: 0.167129-0.724522\n",
      "\n",
      "=== Function 2 (2D) ===\n",
      "  Data size: (12, 2), Output range: [-0.0656, 0.6112]\n",
      "  Best predicted output: 0.7560\n",
      "  Query to submit: 0.868661-0.995937\n",
      "\n",
      "=== Function 3 (3D) ===\n",
      "  Data size: (17, 3), Output range: [-0.3989, -0.0348]\n",
      "  Best predicted output: -0.1209\n",
      "  Query to submit: 0.387719-0.760476-0.452020\n",
      "\n",
      "=== Function 4 (4D) ===\n",
      "  Data size: (32, 4), Output range: [-32.6257, -4.0255]\n",
      "  Best predicted output: -5.0023\n",
      "  Query to submit: 0.348768-0.491521-0.414453-0.271505\n",
      "\n",
      "=== Function 5 (4D) ===\n",
      "  Data size: (22, 4), Output range: [0.1129, 1787.3908]\n",
      "  Best predicted output: 85.2658\n",
      "  Query to submit: 0.152397-0.865019-0.893083-0.890029\n",
      "\n",
      "=== Function 6 (5D) ===\n",
      "  Data size: (22, 5), Output range: [-2.5712, -0.7143]\n",
      "  Best predicted output: -0.6079\n",
      "  Query to submit: 0.566002-0.279903-0.523411-0.730527-0.172090\n",
      "\n",
      "=== Function 7 (6D) ===\n",
      "  Data size: (32, 6), Output range: [0.0027, 1.3650]\n",
      "  Best predicted output: 1.2672\n",
      "  Query to submit: 0.072865-0.350233-0.515085-0.029091-0.365974-0.845134\n",
      "\n",
      "=== Function 8 (8D) ===\n",
      "  Data size: (42, 8), Output range: [5.5922, 9.5985]\n",
      "  Best predicted output: 9.8934\n",
      "  Query to submit: 0.163121-0.457396-0.035635-0.429747-0.481268-0.439640-0.446278-0.788218\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# === 1. CONFIGURATION ===\n",
    "base_path = \"data/\"\n",
    "inputs_txt = \"week2/inputs.txt\"\n",
    "outputs_txt = \"week2/outputs.txt\"\n",
    "\n",
    "# === 2. LOAD INPUTS ===\n",
    "with open(inputs_txt, \"r\") as f:\n",
    "    text = f.read().strip()\n",
    "\n",
    "# Pisahkan jadi 2 batch: minggu 1 dan minggu 2\n",
    "batches = re.findall(r'\\[array\\([^\\]]+\\)\\]', text, re.DOTALL)\n",
    "chunks = text.split(\"]\\n[\")  # pisah antar baris\n",
    "latest_batch = chunks[-1]    # ambil batch terakhir (week 2)\n",
    "text_clean = re.sub(r'array\\(', '', latest_batch).replace(')', '')\n",
    "new_inputs = ast.literal_eval(\"[\" + text_clean.strip().strip('[]') + \"]\")\n",
    "new_inputs = [np.array(x, dtype=float) for x in new_inputs]\n",
    "\n",
    "# === 3. LOAD OUTPUTS ===\n",
    "with open(outputs_txt, \"r\") as f:\n",
    "    text_out = f.read().strip()\n",
    "chunks_out = text_out.split(\"]\\n[\")\n",
    "latest_batch_out = chunks_out[-1]\n",
    "text_clean_out = latest_batch_out.replace(\"np.float64(\", \"\").replace(\")\", \"\")\n",
    "new_outputs = np.array(ast.literal_eval(\"[\" + text_clean_out.strip().strip('[]') + \"]\"), dtype=float)\n",
    "\n",
    "print(f\"✅ Loaded {len(new_inputs)} new inputs and {len(new_outputs)} outputs (latest batch).\")\n",
    "\n",
    "# === 4. PROCESS EACH FUNCTION WITH SVM ===\n",
    "for i in range(1, 9):\n",
    "    folder = os.path.join(base_path, f\"function_{i}\")\n",
    "    input_file = os.path.join(folder, \"week2_inputs.npy\")\n",
    "    output_file = os.path.join(folder, \"week2_outputs.npy\")\n",
    "\n",
    "    # Load data minggu lalu (hasil Linear Regression)\n",
    "    X_prev = np.load(input_file)\n",
    "    y_prev = np.load(output_file)\n",
    "\n",
    "    # Gabungkan dengan hasil minggu lalu\n",
    "    X_combined = np.vstack([X_prev, new_inputs[i - 1].reshape(1, -1)])  # 12 titik\n",
    "    y_combined = np.append(y_prev, new_outputs[i - 1])\n",
    "\n",
    "    # Simpan versi updated\n",
    "    np.save(os.path.join(folder, \"week3_inputs.npy\"), X_combined)\n",
    "    np.save(os.path.join(folder, \"week3_outputs.npy\"), y_combined)\n",
    "\n",
    "    dim = X_combined.shape[1]\n",
    "    print(f\"\\n=== Function {i} ({dim}D) ===\")\n",
    "    print(f\"  Data size: {X_combined.shape}, Output range: [{y_combined.min():.4f}, {y_combined.max():.4f}]\")\n",
    "\n",
    "    # === TRAIN SVM MODEL ===\n",
    "    model = make_pipeline(StandardScaler(), SVR(kernel='rbf', C=5, gamma='scale'))\n",
    "    model.fit(X_combined, y_combined)\n",
    "\n",
    "    # === GENERATE NEW QUERY ===\n",
    "    candidates = np.random.uniform(0, 1, (2000, dim))\n",
    "    preds = model.predict(candidates)\n",
    "    best_idx = np.argmax(preds)\n",
    "    best_query = np.clip(candidates[best_idx], 0.0, 1.0)\n",
    "\n",
    "    # === OUTPUT RESULT ===\n",
    "    query_str = \"-\".join([f\"{x:.6f}\" for x in best_query])\n",
    "    print(f\"  Best predicted output: {preds[best_idx]:.4f}\")\n",
    "    print(f\"  Query to submit: {query_str}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
