{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64a33b83-c220-4d37-bc01-1d03913d27d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Parsed 8 input vectors (latest batch only).\n",
      "âœ… Parsed 8 outputs (latest batch only).\n",
      "\n",
      "=== Function 1 (2D) ===\n",
      "  Data size: 19, Output range: [-0.0036, 64.0000]\n",
      "  Best predicted output: 27.4823\n",
      "  Query to submit: 0.134004-0.569748\n",
      "\n",
      "=== Function 2 (2D) ===\n",
      "  Data size: 19, Output range: [-0.0656, 3.1124]\n",
      "  Best predicted output: 0.7968\n",
      "  Query to submit: 0.739313-0.722208\n",
      "\n",
      "=== Function 3 (3D) ===\n",
      "  Data size: 24, Output range: [-0.3989, 71.0000]\n",
      "  Best predicted output: 19.3789\n",
      "  Query to submit: 0.189178-0.625108-0.708724\n",
      "\n",
      "=== Function 4 (4D) ===\n",
      "  Data size: 39, Output range: [-32.6257, 64.0000]\n",
      "  Best predicted output: -0.9950\n",
      "  Query to submit: 0.363422-0.431794-0.364787-0.419088\n",
      "\n",
      "=== Function 5 (4D) ===\n",
      "  Data size: 29, Output range: [0.1129, 4440.5227]\n",
      "  Best predicted output: 3094.4953\n",
      "  Query to submit: 0.109443-0.976541-0.999893-0.922674\n",
      "\n",
      "=== Function 6 (5D) ===\n",
      "  Data size: 29, Output range: [-2.5712, 64.0000]\n",
      "  Best predicted output: 25.7313\n",
      "  Query to submit: 0.433696-0.061394-0.080104-0.780392-0.238688\n",
      "\n",
      "=== Function 7 (6D) ===\n",
      "  Data size: 39, Output range: [-0.0787, 2.0091]\n",
      "  Best predicted output: 1.5034\n",
      "  Query to submit: 0.005469-0.222784-0.138439-0.335296-0.457795-0.942935\n",
      "\n",
      "=== Function 8 (8D) ===\n",
      "  Data size: 49, Output range: [5.5922, 64.0000]\n",
      "  Best predicted output: 26.9552\n",
      "  Query to submit: 0.085358-0.263317-0.306477-0.455469-0.660197-0.675033-0.020567-0.937765\n",
      "\n",
      "ðŸ’¾ Saved all week10 queries to week10_queries.txt\n",
      "ðŸ§  Detailed explanations saved to week10_logs/week10_explanations.json\n",
      "ðŸ“Š Plots saved under week10_logs/\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import json\n",
    "import datetime\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# CONFIGURATION\n",
    "# =========================\n",
    "base_path = \"data/\"\n",
    "inputs_txt = \"week9/inputs.txt\"       # file dari email (hasil minggu sebelumnya)\n",
    "outputs_txt = \"week9/outputs.txt\"\n",
    "n_candidates = 4000\n",
    "log_folder = \"week10_logs\"\n",
    "\n",
    "# Buat folder log jika belum ada\n",
    "os.makedirs(log_folder, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# LOAD INPUTS (ambil batch terakhir)\n",
    "# =========================\n",
    "def load_inputs(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        text = f.read().strip()\n",
    "    batches = re.split(r\"\\]\\s*\\n\\s*\\[\", text)\n",
    "    last_batch = \"[\" + batches[-1].strip().lstrip(\"[\").rstrip(\"]\") + \"]\"\n",
    "    last_batch = re.sub(r'array\\(', '', last_batch).replace(')', '')\n",
    "    chunks = re.findall(r'\\[([^\\[\\]]+)\\]', last_batch)\n",
    "\n",
    "    vectors = []\n",
    "    for ch in chunks:\n",
    "        nums = [float(x) for x in ch.split(\",\") if x.strip()]\n",
    "        vectors.append(np.array(nums))\n",
    "    print(f\"âœ… Parsed {len(vectors)} input vectors (latest batch only).\")\n",
    "    return vectors\n",
    "\n",
    "# =========================\n",
    "# LOAD OUTPUTS (ambil batch terakhir)\n",
    "# =========================\n",
    "def load_outputs(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        text = f.read().strip()\n",
    "    batches = re.split(r\"\\]\\s*\\n\\s*\\[\", text)\n",
    "    last_batch = batches[-1].strip()\n",
    "    last_batch = last_batch.replace(\"np.float64(\", \"\").replace(\")\", \"\")\n",
    "    last_batch = last_batch.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    last_batch = re.sub(r\"[^\\deE\\-\\.\\,\\s]\", \"\", last_batch)\n",
    "\n",
    "    numbers = re.findall(r\"[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?\", last_batch)\n",
    "    outputs = np.array([float(x) for x in numbers], dtype=float)\n",
    "    print(f\"âœ… Parsed {len(outputs)} outputs (latest batch only).\")\n",
    "    return outputs\n",
    "\n",
    "\n",
    "# =========================\n",
    "# LOAD DATA FROM EMAIL\n",
    "# =========================\n",
    "new_inputs = load_inputs(inputs_txt)\n",
    "new_outputs = load_outputs(outputs_txt)\n",
    "\n",
    "# =========================\n",
    "# MODEL TRAINING & EXPLANATION LOGGING\n",
    "# =========================\n",
    "queries_out = []\n",
    "explanations = {}\n",
    "\n",
    "for i in range(1, 9):\n",
    "    folder = os.path.join(base_path, f\"function_{i}\")\n",
    "    input_file = os.path.join(folder, \"week9_inputs.npy\")\n",
    "    output_file = os.path.join(folder, \"week9_outputs.npy\")\n",
    "\n",
    "    # Gabungkan data lama + batch baru\n",
    "    X_prev = np.load(input_file)\n",
    "    y_prev = np.load(output_file)\n",
    "    X_combined = np.vstack([X_prev, new_inputs[i - 1].reshape(1, -1)])\n",
    "    y_combined = np.append(y_prev, new_outputs[i - 1])\n",
    "\n",
    "    np.save(os.path.join(folder, \"week10_inputs.npy\"), X_combined)\n",
    "    np.save(os.path.join(folder, \"week10_outputs.npy\"), y_combined)\n",
    "\n",
    "    dim = X_combined.shape[1]\n",
    "    print(f\"\\n=== Function {i} ({dim}D) ===\")\n",
    "    print(f\"  Data size: {len(X_combined)}, Output range: [{y_combined.min():.4f}, {y_combined.max():.4f}]\")\n",
    "\n",
    "    # MLP surrogate (same as Week 9 for consistency)\n",
    "    model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        MLPRegressor(\n",
    "            hidden_layer_sizes=(512, 256, 128),\n",
    "            activation='relu',\n",
    "            solver='adam',\n",
    "            alpha=3e-4,\n",
    "            learning_rate_init=0.001,\n",
    "            max_iter=3000,\n",
    "            random_state=42\n",
    "        )\n",
    "    )\n",
    "    model.fit(X_combined, y_combined)\n",
    "\n",
    "    # --- Plot performance for transparency ---\n",
    "    y_pred_train = model.predict(X_combined)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(y_combined, y_pred_train, c='blue', edgecolor='k')\n",
    "    plt.plot([y_combined.min(), y_combined.max()],\n",
    "             [y_combined.min(), y_combined.max()],\n",
    "             'r--', lw=2)\n",
    "    plt.title(f'Function {i} - Actual vs Predicted (Week 10)')\n",
    "    plt.xlabel('Actual y')\n",
    "    plt.ylabel('Predicted y')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(log_folder, f\"function_{i}_fit.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # --- Candidate search ---\n",
    "    candidates = np.random.uniform(0, 1, (n_candidates, dim))\n",
    "    preds = model.predict(candidates)\n",
    "    top_indices = np.argsort(preds)[-5:][::-1]  # ambil 5 tertinggi\n",
    "    best_idx = top_indices[0]\n",
    "    best_query = np.clip(candidates[best_idx], 0.0, 1.0)\n",
    "    query_str = \"-\".join([f\"{x:.6f}\" for x in best_query])\n",
    "\n",
    "    print(f\"  Best predicted output: {preds[best_idx]:.4f}\")\n",
    "    print(f\"  Query to submit: {query_str}\")\n",
    "\n",
    "    # --- Explanation log ---\n",
    "    explanations[f\"Function_{i}\"] = {\n",
    "        \"timestamp\": str(datetime.datetime.now()),\n",
    "        \"dimensionality\": dim,\n",
    "        \"data_points_used\": len(X_combined),\n",
    "        \"output_range\": [float(y_combined.min()), float(y_combined.max())],\n",
    "        \"model_architecture\": [512, 256, 128],\n",
    "        \"top_5_predictions\": preds[top_indices].tolist(),\n",
    "        \"top_5_candidates\": candidates[top_indices].tolist(),\n",
    "        \"selected_query\": best_query.tolist(),\n",
    "        \"reasoning\": (\n",
    "            \"Selected based on highest predicted output from MLP surrogate. \"\n",
    "            \"Query chosen from top-5 candidate set to prioritise stable, high-value regions \"\n",
    "            \"identified by model confidence and historical performance trends.\"\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    queries_out.append(f\"Function {i}: {query_str}\")\n",
    "\n",
    "# =========================\n",
    "# SAVE WEEK10 QUERIES + LOGS\n",
    "# =========================\n",
    "with open(\"week10_queries.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(queries_out))\n",
    "\n",
    "with open(os.path.join(log_folder, \"week10_explanations.json\"), \"w\") as f:\n",
    "    json.dump(explanations, f, indent=4)\n",
    "\n",
    "print(\"\\nðŸ’¾ Saved all week10 queries to week10_queries.txt\")\n",
    "print(\"ðŸ§  Detailed explanations saved to week10_logs/week10_explanations.json\")\n",
    "print(\"ðŸ“Š Plots saved under week10_logs/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml311)",
   "language": "python",
   "name": "ml311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
